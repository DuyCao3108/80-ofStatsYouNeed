{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libs\n",
    "import pandas as pd\n",
    "import openpyxl # to read xlsx\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels\n",
    "import scipy.stats\n",
    "# Chisquare\n",
    "from scipy.stats import chisquare\n",
    "# ANOVA\n",
    "from scipy.stats import f_oneway\n",
    "# Wilcoxon\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import ranksums\n",
    "import pingouin as pg \n",
    "# Normality testing\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import anderson\n",
    "# Trim_mean function\n",
    "from scipy.stats import trim_mean\n",
    "# Hypothesis testingg\n",
    "from scipy.stats import t\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_ind_from_stats \n",
    "# Sampling\n",
    "import random\n",
    "from random import sample\n",
    "from sklearn.utils import resample\n",
    "# Linear regression\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is used to block warning messages\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Or ignore specific warnings by category (e.g., FutureWarnings)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# This is used to edit image\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = pd.read_excel(r'C:\\Users\\Admin\\Dognition\\_1e0dffe5f998bae66fea694bbcc0fd99_dognition_data_no_aggregation_with_zip_code_correction.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> How to sample a normal distribution and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample and plot normal dist\n",
    "np.random.seed(31)\n",
    "x = np.random.randn(1000,)\n",
    "sns.kdeplot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To examine normality of a data set, you can:\n",
    "> * Visualize the data and see if it has the bell-curved shape\n",
    "> * Visualize the data on qqplot. If the data is heavily distributed around the diagonal line, then it's likely to have a normal distribution\n",
    "> * Use statistical test (recommnended). There are several tests to use, such as Shapiro, or Anderson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine using qqplot\n",
    "ax = qqplot(x, line='s')\n",
    "plt.show(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As you can see, this data is normally distributed and when plot it on qqplot, data points are centered around the red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro test for normality\n",
    "shapiro(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The null hypothesis of shapiro test is: Data follows normal distribution. \n",
    "> Pvalue of the test is less than 1-5-10%, meaning the null hypothesis is accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anderson\n",
    "print(anderson(x).significance_level,\n",
    "      anderson(x).critical_values,\n",
    "      anderson(x).statistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Anderson test's H0 statese that the data follow a particular distribution. As default, the examined distribution is the Gaussian (normal)\n",
    "> \n",
    "> To check the result:\n",
    "> * Choose desired significant level (it is the alpha)\n",
    "> * Get critical value assigned with that level of significance\n",
    "> * Compare test statistic with the critical value. If Test statistic < Critical value, then accept Null hypothesis and vice versa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Descriptive Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> There are several main aspects of the data that we hope to describe: \n",
    "> * <strong> Location.</strong> location shows the value that the data center around\n",
    "> * <strong>Dispersion.</strong> Dispersion shows how far the data is compared to its location\n",
    "> * <strong>Correlation.</strong> Correlation shows the strength and direction of two variables' relationship. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### LOCATION #######\n",
    "# data\n",
    "data = df['Rank_by_DogID'].dropna()\n",
    "# mean\n",
    "print('mean', data.mean())\n",
    "# trim-mean (from scipy.stats import trim_mean)\n",
    "print('trim-mean', trim_mean(data, 0.1))\n",
    "# median\n",
    "print('median', data.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### DISPERSION ######\n",
    "# data\n",
    "data = df['Rank_by_DogID'].dropna()\n",
    "# standard deviation, variance\n",
    "print('standard deviation', data.std(), \"variance\", data.std() ** 2)\n",
    "# quantile\n",
    "data1 = data.values\n",
    "quantiles = [q/10 for q in range(2,10,2)]\n",
    "for quan in quantiles:\n",
    "    print(f\"quantile {quan} \", np.quantile(data1, quan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### CORRELATION #######\n",
    "# data \n",
    "data_corre = df.dropna(subset=['Sign_in_Count', 'Rank_by_UserID'])\n",
    "x = data_corre['Sign_in_Count']\n",
    "y = data_corre['Rank_by_UserID']\n",
    "# covariance\n",
    "cov_matrix = pd.DataFrame(np.cov(x,y), index=('x','y'), columns=['x','y'])\n",
    "# correlation coefficient\n",
    "corrcoef_matrix = pd.DataFrame(np.corrcoef(x,y), index=('x','y'), columns=['x','y'])\n",
    "# display result\n",
    "display(\n",
    "    \"cov_matrix: \", cov_matrix,\n",
    "    \"covariance of x - y: \", cov_matrix.loc[\"x\",\"y\"],\n",
    "    'corrcoef_matrix: ', corrcoef_matrix,\n",
    "    \"corrcoef of x - y: \", corrcoef_matrix.loc[\"x\",\"y\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PROBABILITY (Distribution) #####\n",
    "# data\n",
    "data = df['Rank_by_DogID'].dropna()\n",
    "data_dist = (data.values / sum(data)) * 100\n",
    "\n",
    "print('THIS IS THE PROB TABLE')\n",
    "pd.DataFrame(\n",
    "    {\"value\" : list(data.values),\n",
    "    \"probability\" : list(data_dist)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe function\n",
    "df[['Rank_by_UserID','Sign_in_Count']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The boxplot\n",
    "sns.boxplot(df['Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The violin\n",
    "sns.violinplot(df['Weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical data visualization\n",
    "sns.catplot(\n",
    "    data = df[['Gender','Weight']],\n",
    "    x = 'Gender',\n",
    "    y = 'Weight',\n",
    "    kind = 'violin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatter plot\n",
    "sns.scatterplot(\n",
    "    data = pd.DataFrame(np.random.randn(1000,2),columns=[\"x\",\"y\"]),\n",
    "    x = \"x\",\n",
    "    y = 'y',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat map\n",
    "data = df[['Rank_by_UserID','Sign_in_Count','Max_Dogs']].dropna()\n",
    "corre_matrix = np.corrcoef(data.T)\n",
    "\n",
    "display(corre_matrix)\n",
    "sns.heatmap(corre_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot\n",
    "data = pd.DataFrame(np.random.randn(100,3),columns=[\"x\",\"y\",\"z\"])\n",
    "sns.pairplot(data, kind =\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Range Estimation - Confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> With the observed data, we can estimate the value range that the data' parameters (mean, standard deviation,...) fall into. \n",
    ">\n",
    "> The steps for calculation are:\n",
    "> * Get the number of observation (n)\n",
    "> * Get the location (mean)\n",
    "> * Get the dispersion (standard deviation)\n",
    "> * Get the standard error by dividing the Standard deviation with square of n\n",
    "> * Get the t value for the desired significant level\n",
    "> * Combine those value using this formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The San Juan Mountains are beautiful!](\\Image\\Confidence-Interval-Formula.jpg \"San Juan Mountains\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = df['Rank_by_DogID'].dropna()\n",
    "# Number of observation\n",
    "n = len(data)\n",
    "# Mean\n",
    "X_bar = data.mean()\n",
    "# Standard deviation\n",
    "StanD = np.std(data)\n",
    "# Standard error\n",
    "StanE = StanD / np.sqrt(n) # sigma/sqrt(n)\n",
    "# t-Value\n",
    "t_val = t.ppf(0.95, df=n-1) # ppf take first argument as the quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confidence interval\n",
    "con_inv = (X_bar - t_val*StanE, X_bar + t_val*StanE)\n",
    "con_inv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Hypothesis testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <p> \n",
    "> Hypothesis testing is a broad topic with numerous existing methods. <br>\n",
    "> In this section, we cover the most basic yet widely used test, which is T test for mean of one and two samples. <br>\n",
    "> <ul>\n",
    "> <strong> Why examine the mean</strong>: Most of the time, the average value of data sets can give enough information for us to check our hypotheses.  <br>\n",
    "> <strong> Why using T value</strong>: Student distribution (t) has the same bell-curved shape as the Gaussian distribution. However, t distribution is <br>\n",
    "> more flexible since we can use its value for data that has small size or when we does not know the sigma of population. Moreover, when observation size <br>\n",
    "> increase, the t distribution is approximately identical to the Gaussian distribution.\n",
    ">  <br>\n",
    "> </ul>\n",
    "> </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ONE SAMPLE T-TEST #####\n",
    "data = df['Rating'].dropna().values\n",
    "# H1: Mean of Rating > 2.5\n",
    "ttest_1samp(data, popmean = 2.5, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.0686681511758527, pvalue=0.14388337177925895)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### TWO SAMPLES T-TEST #####\n",
    "rating_of_tested = df[df['DNA_Tested'] == 1]['Rating'].dropna().values\n",
    "rating_of_no_tested = df[df['DNA_Tested'] == 0]['Rating'].dropna().values\n",
    "# H1: Rating of DNA_Tested > Rating of DNA_Not_Tetsted\n",
    "ttest_ind_from_stats(\n",
    "    mean1 = rating_of_tested.mean(), std1 = np.std(rating_of_tested), nobs1 = len(rating_of_tested), \n",
    "    mean2 = rating_of_no_tested.mean(), std2 = np.std(rating_of_no_tested), nobs2 = len(rating_of_no_tested),\n",
    "    alternative = 'greater'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chisquare Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Chisquare tests are mostly used to confirm the distribution of a data set. <br>\n",
    "The H0 in chisquare tests is that the data <strong> does not </strong> follow a particular distribution. <br>\n",
    "The chisquare tests are used in problems such as:\n",
    "<ul>\n",
    "- Confirming the data has a normal distribution, or any other interested common distribution. <br>\n",
    "- Examine the relationship between two categorical variables. <br>\n",
    "</ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution Hypothesis test (Goodness-of-fit Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi = df.groupby(['DNA_Tested','Subscribed']).agg({'User_ID':'count'}).reset_index()\n",
    "chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename\n",
    "chi = chi.rename(columns={'User_ID':'Obser_count'})\n",
    "# take expected distribution\n",
    "chi['Exp_dist'] = 1/ len(chi['Subscribed'].unique())\n",
    "# generate a column with the total sample of tested and not tested DNA - dog\n",
    "chi['Total_sample'] = chi.groupby('DNA_Tested')['Obser_count'].transform(sum)\n",
    "# Get expected count\n",
    "chi['Exp_count'] = chi['Total_sample'] * chi['Exp_dist']\n",
    "# Get observed distribution\n",
    "chi['Obs_dist'] = chi['Obser_count'] / chi['Total_sample']\n",
    "# Take only the distribution columns to compare\n",
    "chi[['DNA_Tested','Subscribed', 'Obs_dist','Exp_dist']]\n",
    "# print(0.630765 - 0.369235, 0.592443- 0.407557) # compare the diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the hypothesis\n",
    "f_obs = chi['Obser_count'].values\n",
    "f_exp = chi['Exp_count'].values\n",
    "chisquare(f_obs,f_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variance (ANOVA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <p>\n",
    "> The Analysis of Variance is unique in terms of enabling hypothesis testing for more than two samples.\n",
    "> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Rank_by_DogID']).groupby('Dimension')['Rank_by_DogID'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_sample = []\n",
    "for dimension in df['Dimension'].dropna().unique():\n",
    "    sam = df[df['Dimension'] == dimension]['Rank_by_DogID'].dropna()\n",
    "    list_of_sample.append(np.array(sam))\n",
    "list_of_sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oneway(list_of_sample[0],\n",
    "        list_of_sample[1],\n",
    "        list_of_sample[2],\n",
    "        list_of_sample[3],\n",
    "        list_of_sample[4],\n",
    "        list_of_sample[5],\n",
    "        list_of_sample[6],\n",
    "        list_of_sample[7],\n",
    "        list_of_sample[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Welch ANOVA is used when prerequisites in ANOVA is not met.\n",
    ">\n",
    "> Those prerequisites are: Groups have equal variance, Normal distribution, Large enough sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welch ANOVA\n",
    "pg.welch_anova(dv= 'Rank_by_DogID', between= 'Dimension', data= df.dropna(subset=['Dimension','Rank_by_DogID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: ANOVA is typically used to examine the difference between means of groups, which are divided by one categorical variable.\n",
    ">\n",
    "> Regression with dummy variable can replace ANOVA if wanted. However Regression with dummy variable is more suitable when there are more than one categorical variables and when the purpose is to examine the relationship between factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-parametric Methods (Wilconxon test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> When assumption about the normality of data is not met, one common non-parametric method which is the wilconxon test is used. <br>\n",
    "> Wilconxon test ignore mean and variance of the data. This method cares only about <strong> the median </strong>, which is not affected by the distribution of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample / Two paired samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One sample - Rating\n",
    "data = df['Rating'].dropna().values\n",
    "print(np.median(data))\n",
    "print(wilcoxon(data-2.5, alternative='greater'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two independent samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male = df[df['Gender'] == 'male']['Rating'].dropna().values\n",
    "female = df[df['Gender'] == 'female']['Rating'].dropna().values\n",
    "\n",
    "print(len(male),len(female))\n",
    "print(np.median(male) , np.median(female))\n",
    "\n",
    "sns.boxplot([male,female])\n",
    "\n",
    "ranksums(x=male,y=female,alternative='greater')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstraping / Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The last thing we will cover is sampling methods, particularly bootstraping and permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brief introduction about bootstraping:**\n",
    "\n",
    "* Its a Resampling method.\n",
    "* Estimates sampling distribution by repeatedly drawing samples with replacement.\n",
    "* Useful when population distribution is unknown or sample size is limited.\n",
    "* Calculates confidence intervals, standard errors, and assesses uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regresion on \"Sign_in_Count\" -> \"Rank_by_UserID\"\n",
    "sign_in_rank = df[['Sign_in_Count','Rank_by_UserID']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample function\n",
    "ori = sign_in_rank[['Sign_in_Count','Rank_by_UserID']]\n",
    "sampled = resample(sign_in_rank[['Sign_in_Count','Rank_by_UserID']])\n",
    "display('ori: ', ori.mean(), 'sampled: ', sampled.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boostraping_for_sign_rank_problem(data, times):\n",
    "    result_list = []\n",
    "    for boostrap_time in range(times):\n",
    "        # sampling data\n",
    "        sample_data = resample(data)\n",
    "        model = LinearRegression()\n",
    "        model.fit(sample_data[['Sign_in_Count']],sample_data[['Rank_by_UserID']])\n",
    "        result_list.append(model.coef_[0][0])\n",
    "    return np.array(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ar = boostraping_for_sign_rank_problem(sign_in_rank, times = 100)\n",
    "# see its distribution\n",
    "sns.kdeplot(res_ar)\n",
    "# calculate the average value from every sample\n",
    "print(\"Average coeff: \", np.mean(res_ar))\n",
    "print(\"Original coeff: \", LinearRegression().fit(sign_in_rank[['Sign_in_Count']],sign_in_rank[['Rank_by_UserID']]).coef_[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Brief introduction about permutation:**\n",
    "\n",
    "* Its a Non-parametric statistical method.\n",
    "* Assesses significance without assuming specific population distributions.\n",
    "* Involves shuffling or rearranging data points to create a null distribution.\n",
    "* Valuable for non-normal data and when parametric assumptions don't hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNA tested has higher rating than DNA not tested\n",
    "rating_dnatest = df[['Rating','DNA_Tested']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for normality\n",
    "sns.kdeplot(rating_dnatest.Rating)\n",
    "shapiro(rating_dnatest[['Rating']]) # conclusion: not normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed test statistic\n",
    "mean_test = rating_dnatest[rating_dnatest['DNA_Tested'] == 1]['Rating'].mean()\n",
    "mean_not_test = rating_dnatest[rating_dnatest['DNA_Tested'] == 0]['Rating'].mean()\n",
    "test_statistic = mean_test - mean_not_test\n",
    "print('mean_test: ',mean_test,'mean_not_test: ',mean_not_test, 'test_statistic: ', test_statistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutating(data, n_group1, times):\n",
    "    permutation_result = []\n",
    "    for permu_time in range(times):\n",
    "        sample_data = data.sample(len(data))\n",
    "        sample_group1 = sample_data[:n_group1]\n",
    "        sample_group2 = sample_data[n_group1:]\n",
    "        # get value to get from sample\n",
    "        sample_result = sample_group1.mean() - sample_group2.mean()\n",
    "        permutation_result.append(sample_result)\n",
    "    return np.array(permutation_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_group1 = len(rating_dnatest[rating_dnatest['DNA_Tested'] == 1]['Rating'])\n",
    "df_res = permutating(rating_dnatest[['DNA_Tested']], n_group1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_p_value(res_permu, observed_test_statistic):\n",
    "    count_extreme_than_stat = len(res_permu[res_permu > observed_test_statistic])\n",
    "    p_value = count_extreme_than_stat / len(res_permu) \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_p_value(df_res, test_statistic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
